Metadata-Version: 2.1
Name: langchain-llama-stack
Version: 0.1.0
Summary: An integration package connecting LlamaStack and LangChain
Home-page: https://github.com/langchain-ai/langchain
License: MIT
Requires-Python: >=3.9,<4.0
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Dist: langchain-core (>=0.3.47,<0.4.0)
Requires-Dist: llama-stack-client (>=0.1.8,<0.2.0)
Project-URL: Repository, https://github.com/langchain-ai/langchain
Project-URL: Release Notes, https://github.com/mattf/langchain-llama-stack/releases
Project-URL: Source Code, https://github.com/mattf/langchain-llama-stack
Description-Content-Type: text/markdown

# langchain-llama-stack

This package contains the LangChain integration with [Llama Stack](https://github.com/meta-llama/llama-stack).

## Installation

```bash
pip install -U langchain-llama-stack
```

If your Llama Stack distribution requires credentials, use the `LLAMA_STACK_API_KEY` environment variable.

If your Llama Stack distribution server is not running on `http://localhost:8321`, use the `LLAMA_STACK_BASE_URL` environment variable.

## Chat Models

`ChatLlamaStack` class exposes chat models, which are hosted at `/v1/inference/chat-completion` on your Llama Stack distribution server.

```python
from langchain_llama_stack import ChatLlamaStack

llm = ChatLlamaStack(model="meta/llama-3.1-8b-instruct")
llm.invoke("Sing a ballad of LangChain.")
```

