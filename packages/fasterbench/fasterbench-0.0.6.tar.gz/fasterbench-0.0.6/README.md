# fasterbench


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

[![PyPI
version](https://badge.fury.io/py/fasterbench.svg)](https://badge.fury.io/py/fasterbench)
[![License:
MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## Overview

`fasterbench` is a powerful benchmarking library designed to help AI
researchers and engineers evaluate PyTorch models across multiple
dimensions:

- **Size**: Model disk size and parameter count
- **Speed**: GPU and CPU latency and throughput
- **Compute**: MACs (multiply-accumulate operations)
- **Memory**: GPU memory usage
- **Energy**: Power consumption and carbon emissions

Whether youâ€™re optimizing for deployment, comparing architectures, or
researching model efficiency, `fasterbench` provides the metrics you
need to make informed decisions.

## Installation

``` bash
pip install fasterbench
```

## Quick Start

``` python
import torch
from torchvision.models import resnet18
from fasterbench import benchmark

# Load your model
model = resnet18()

# Create sample input
dummy_input = torch.randn(1, 3, 224, 224)

# Run comprehensive benchmarks
results = benchmark(model, dummy_input)
```

## Features

- **All-in-one benchmarking**: Get comprehensive metrics with a single
  function call
- **GPU and CPU performance**: Compare inference speed across different
  hardware
- **Environmental impact**: Measure carbon footprint with CodeCarbon
  integration
- **Memory profiling**: Track peak and average GPU memory usage
- **Model comparison**: Easily visualize differences between model
  variants

## Example: Comparing Models

``` python
from fasterbench import compare_models
from torchvision.models import resnet18, resnet34, resnet50

# Define your models
models = [resnet18(), resnet34(), resnet50()]

# Compare metrics across models
compare_models(models, dls)
```

## Documentation

For more detailed usage examples and API documentation, visit our
[documentation](https://github.com/nathanhubens/fasterbench).

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the MIT License - see the LICENSE file
for details.
