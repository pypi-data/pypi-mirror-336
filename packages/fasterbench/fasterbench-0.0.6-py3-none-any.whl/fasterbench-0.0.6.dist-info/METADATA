Metadata-Version: 2.1
Name: fasterbench
Version: 0.0.6
Summary: A library for benchmarking AI models
Home-page: https://github.com/FasterAI-Labs/fasterbench
Author: nathanhubens
Author-email: nathan.hubens@gmail.com
License: Apache Software License 2.0
Keywords: nbdev jupyter notebook python
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Natural Language :: English
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: License :: OSI Approved :: Apache Software License
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: torch
Requires-Dist: fastcore
Requires-Dist: prettytable
Requires-Dist: tqdm
Requires-Dist: codecarbon
Requires-Dist: torchprofile
Requires-Dist: thop
Provides-Extra: dev

# fasterbench


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

[![PyPI
version](https://badge.fury.io/py/fasterbench.svg)](https://badge.fury.io/py/fasterbench)
[![License:
MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## Overview

`fasterbench` is a powerful benchmarking library designed to help AI
researchers and engineers evaluate PyTorch models across multiple
dimensions:

- **Size**: Model disk size and parameter count
- **Speed**: GPU and CPU latency and throughput
- **Compute**: MACs (multiply-accumulate operations)
- **Memory**: GPU memory usage
- **Energy**: Power consumption and carbon emissions

Whether youâ€™re optimizing for deployment, comparing architectures, or
researching model efficiency, `fasterbench` provides the metrics you
need to make informed decisions.

## Installation

``` bash
pip install fasterbench
```

## Quick Start

``` python
import torch
from torchvision.models import resnet18
from fasterbench import benchmark

# Load your model
model = resnet18()

# Create sample input
dummy_input = torch.randn(1, 3, 224, 224)

# Run comprehensive benchmarks
results = benchmark(model, dummy_input)
```

## Features

- **All-in-one benchmarking**: Get comprehensive metrics with a single
  function call
- **GPU and CPU performance**: Compare inference speed across different
  hardware
- **Environmental impact**: Measure carbon footprint with CodeCarbon
  integration
- **Memory profiling**: Track peak and average GPU memory usage
- **Model comparison**: Easily visualize differences between model
  variants

## Example: Comparing Models

``` python
from fasterbench import compare_models
from torchvision.models import resnet18, resnet34, resnet50

# Define your models
models = [resnet18(), resnet34(), resnet50()]

# Compare metrics across models
compare_models(models, dls)
```

## Documentation

For more detailed usage examples and API documentation, visit our
[documentation](https://github.com/nathanhubens/fasterbench).

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the MIT License - see the LICENSE file
for details.
