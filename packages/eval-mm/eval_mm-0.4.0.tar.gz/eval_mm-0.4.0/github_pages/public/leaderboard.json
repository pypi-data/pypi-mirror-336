[
  {
    "model": "stabilityai/japanese-instructblip-alpha",
    "url": "https://huggingface.co/stabilityai/japanese-instructblip-alpha",
    "scores": {
      "Heron": {
        "LLM": 23.53
      },
      "VG-VQA": {
        "LLM": 2.97,
        "Rouge": 34.06
      },
      "JIC": {
        "Acc": 0.57
      },
      "MECHA": {
        "Acc": 0.23
      },
      "MMMU": {
        "Acc": 0.26
      },
      "JVB-ItW": {
        "LLM": 2.26,
        "Rouge": 14.17
      },
      "LLAVA": {
        "LLM": 1.25,
        "Rouge": 0.15
      },
      "JDocQA": {
        "Acc": 0.12,
        "LLM": 2.08
      },
      "MulIm-VQA": {
        "LLM": 2.44,
        "Rouge": 25.01
      },
      "JMMMU": {
        "Acc": 0.26
      }
    }
  },
  {
    "model": "stabilityai/japanese-stable-vlm",
    "url": "https://huggingface.co/stabilityai/japanese-stable-vlm",
    "scores": {
      "Heron": {
        "LLM": 48.44
      },
      "VG-VQA": {
        "LLM": 3.47,
        "Rouge": 45.72
      },
      "JIC": {
        "Acc": 0.69
      },
      "MECHA": {
        "Acc": 0.05
      },
      "MMMU": {
        "Acc": 0.07
      },
      "JVB-ItW": {
        "LLM": 3.28,
        "Rouge": 23.17
      },
      "LLAVA": {
        "LLM": 1.4,
        "Rouge": 0.58
      },
      "JDocQA": {
        "Acc": 0.13,
        "LLM": 2.09
      },
      "MulIm-VQA": {
        "LLM": 2.33,
        "Rouge": 40.7
      },
      "JMMMU": {
        "Acc": 0.03
      }
    }
  },
  {
    "model": "SakanaAI/Llama-3-EvoVLM-JP-v2",
    "url": "https://huggingface.co/SakanaAI/Llama-3-EvoVLM-JP-v2",
    "scores": {
      "Heron": {
        "LLM": 47.59
      },
      "VG-VQA": {
        "LLM": 3.43,
        "Rouge": 24.67
      },
      "JIC": {
        "Acc": 0.67
      },
      "MECHA": {
        "Acc": 0.51
      },
      "MMMU": {
        "Acc": 0.39
      },
      "JVB-ItW": {
        "LLM": 3.48,
        "Rouge": 48.38
      },
      "LLAVA": {
        "LLM": 2.87,
        "Rouge": 27.88
      },
      "JDocQA": {
        "Acc": 0.15,
        "LLM": 2.35
      },
      "MulIm-VQA": {
        "LLM": 3.13,
        "Rouge": 44.31
      },
      "JMMMU": {
        "Acc": 0.36
      }
    }
  },
  {
    "model": "cyberagent/llava-calm2-siglip",
    "url": "https://huggingface.co/cyberagent/llava-calm2-siglip",
    "scores": {
      "Heron": {
        "LLM": 54.1
      },
      "VG-VQA": {
        "LLM": 3.57,
        "Rouge": 17.7
      },
      "JIC": {
        "Acc": 0.58
      },
      "MECHA": {
        "Acc": 0.11
      },
      "MMMU": {
        "Acc": 0.27
      },
      "JVB-ItW": {
        "LLM": 3.66,
        "Rouge": 46.27
      },
      "LLAVA": {
        "LLM": 1.95,
        "Rouge": 2.92
      },
      "JDocQA": {
        "Acc": 0.08,
        "LLM": 2.05
      },
      "MulIm-VQA": {
        "LLM": 2.75,
        "Rouge": 40.63
      },
      "JMMMU": {
        "Acc": 0.06
      }
    }
  },
  {
    "model": "llm-jp/llm-jp-3-vila-14b",
    "url": "https://huggingface.co/llm-jp/llm-jp-3-vila-14b",
    "scores": {
      "Heron": {
        "LLM": 68.03
      },
      "VG-VQA": {
        "LLM": 3.93,
        "Rouge": 16.21
      },
      "JIC": {
        "Acc": 0.81
      },
      "MECHA": {
        "Acc": 0.46
      },
      "MMMU": {
        "Acc": 0.33
      },
      "JVB-ItW": {
        "LLM": 4.08,
        "Rouge": 52.38
      },
      "LLAVA": {
        "LLM": 3.35,
        "Rouge": 36.04
      },
      "JDocQA": {
        "Acc": 0.17,
        "LLM": 2.51
      },
      "MulIm-VQA": {
        "LLM": 3.51,
        "Rouge": 46.96
      },
      "JMMMU": {
        "Acc": 0.19
      }
    }
  },
  {
    "model": "sbintuitions/sarashina2-vision-8b",
    "url": "https://huggingface.co/sbintuitions/sarashina2-vision-8b",
    "scores": {
      "Heron": {
        "LLM": 60.45
      },
      "VG-VQA": {
        "LLM": 3.72,
        "Rouge": 25.45
      },
      "JIC": {
        "Acc": 0.79
      },
      "MECHA": {
        "Acc": 0.56
      },
      "MMMU": {
        "Acc": 0.3
      },
      "JVB-ItW": {
        "LLM": 4.06,
        "Rouge": 44.8
      },
      "LLAVA": {
        "LLM": 2.45,
        "Rouge": 16.94
      },
      "JDocQA": {
        "Acc": 0.23,
        "LLM": 2.98
      },
      "MulIm-VQA": {
        "LLM": 2.62,
        "Rouge": 30.2
      },
      "JMMMU": {
        "Acc": 0.39
      }
    }
  },
  {
    "model": "sbintuitions/sarashina2-vision-14b",
    "url": "https://huggingface.co/sbintuitions/sarashina2-vision-14b",
    "scores": {
      "Heron": {
        "LLM": 60.15
      },
      "VG-VQA": {
        "LLM": 3.72,
        "Rouge": 25.34
      },
      "JIC": {
        "Acc": 0.8
      },
      "MECHA": {
        "Acc": 0.64
      },
      "MMMU": {
        "Acc": 0.34
      },
      "JVB-ItW": {
        "LLM": 4.04,
        "Rouge": 44.3
      },
      "LLAVA": {
        "LLM": 2.52,
        "Rouge": 15.59
      },
      "JDocQA": {
        "Acc": 0.24,
        "LLM": 3.07
      },
      "MulIm-VQA": {
        "LLM": 2.64,
        "Rouge": 35.3
      },
      "JMMMU": {
        "Acc": 0.43
      }
    }
  },
  {
    "model": "MIL-UT/Asagi-14B",
    "url": "https://huggingface.co/MIL-UT/Asagi-14B",
    "scores": {
      "Heron": {
        "LLM": 41.85
      },
      "VG-VQA": {
        "LLM": 1.96,
        "Rouge": 9.29
      },
      "JIC": {
        "Acc": 0.76
      },
      "MECHA": {
        "Acc": 0.24
      },
      "MMMU": {
        "Acc": 0.15
      },
      "JVB-ItW": {
        "LLM": 2.9,
        "Rouge": 30.88
      },
      "LLAVA": {
        "LLM": 1.57,
        "Rouge": 0.05
      },
      "JDocQA": {
        "Acc": 0.1,
        "LLM": 1.99
      },
      "MulIm-VQA": {
        "LLM": 2.0,
        "Rouge": 18.39
      },
      "JMMMU": {
        "Acc": 0.22
      }
    }
  },
  {
    "model": "llava-hf/llava-1.5-7b-hf",
    "url": "https://huggingface.co/llava-hf/llava-1.5-7b-hf",
    "scores": {
      "Heron": {
        "LLM": 43.14
      },
      "VG-VQA": {
        "LLM": 2.98,
        "Rouge": 13.97
      },
      "JIC": {
        "Acc": 0.44
      },
      "MECHA": {
        "Acc": 0.38
      },
      "MMMU": {
        "Acc": 0.34
      },
      "JVB-ItW": {
        "LLM": 3.02,
        "Rouge": 40.75
      },
      "LLAVA": {
        "LLM": 2.93,
        "Rouge": 34.55
      },
      "JDocQA": {
        "Acc": 0.15,
        "LLM": 2.17
      },
      "MulIm-VQA": {
        "LLM": 2.55,
        "Rouge": 35.78
      },
      "JMMMU": {
        "Acc": 0.3
      }
    }
  },
  {
    "model": "llava-hf/llava-v1.6-mistral-7b-hf",
    "url": "https://huggingface.co/llava-hf/llava-v1.6-mistral-7b-hf",
    "scores": {
      "Heron": {
        "LLM": 30.04
      },
      "VG-VQA": {
        "LLM": 3.05,
        "Rouge": 11.71
      },
      "JIC": {
        "Acc": 0.58
      },
      "MECHA": {
        "Acc": 0.34
      },
      "MMMU": {
        "Acc": 0.36
      },
      "JVB-ItW": {
        "LLM": 2.92,
        "Rouge": 28.62
      },
      "LLAVA": {
        "LLM": 3.25,
        "Rouge": 30.72
      },
      "JDocQA": {
        "Acc": 0.14,
        "LLM": 1.98
      },
      "MulIm-VQA": {
        "LLM": 2.31,
        "Rouge": 25.22
      },
      "JMMMU": {
        "Acc": 0.25
      }
    }
  },
  {
    "model": "neulab/Pangea-7B-hf",
    "url": "https://huggingface.co/neulab/Pangea-7B-hf",
    "scores": {
      "Heron": {
        "LLM": 56.97
      },
      "VG-VQA": {
        "LLM": 4.13,
        "Rouge": 54.19
      },
      "JIC": {
        "Acc": 0.86
      },
      "MECHA": {
        "Acc": 0.57
      },
      "MMMU": {
        "Acc": 0.44
      },
      "JVB-ItW": {
        "LLM": 3.86,
        "Rouge": 33.54
      },
      "LLAVA": {
        "LLM": 3.52,
        "Rouge": 25.94
      },
      "JDocQA": {
        "Acc": 0.16,
        "LLM": 2.36
      },
      "MulIm-VQA": {
        "LLM": 3.38,
        "Rouge": 40.27
      },
      "JMMMU": {
        "Acc": 0.37
      }
    }
  },
  {
    "model": "mistralai/Pixtral-12B-2409",
    "url": "https://huggingface.co/mistralai/Pixtral-12B-2409",
    "scores": {
      "Heron": {
        "LLM": 60.88
      },
      "VG-VQA": {
        "LLM": 3.52,
        "Rouge": 13.08
      },
      "JIC": {
        "Acc": 0.61
      },
      "MECHA": {
        "Acc": 0.56
      },
      "MMMU": {
        "Acc": 0.49
      },
      "JVB-ItW": {
        "LLM": 3.9,
        "Rouge": 38.29
      },
      "LLAVA": {
        "LLM": 3.63,
        "Rouge": 31.56
      },
      "JDocQA": {
        "Acc": 0.15,
        "LLM": 2.44
      },
      "MulIm-VQA": {
        "LLM": 4.11,
        "Rouge": 34.48
      },
      "JMMMU": {
        "Acc": 0.19
      }
    }
  },
  {
    "model": "meta-llama/Llama-3.2-11B-Vision-Instruct",
    "url": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct",
    "scores": {
      "Heron": {
        "LLM": 38.08
      },
      "VG-VQA": {
        "LLM": 3.32,
        "Rouge": 14.23
      },
      "JIC": {
        "Acc": 0.79
      },
      "MECHA": {
        "Acc": 0.49
      },
      "MMMU": {
        "Acc": 0.38
      },
      "JVB-ItW": {
        "LLM": 3.36,
        "Rouge": 30.43
      },
      "LLAVA": {
        "LLM": 3.7,
        "Rouge": 30.2
      },
      "JDocQA": {
        "Acc": 0.18,
        "LLM": 2.52
      },
      "MulIm-VQA": {
        "LLM": 2.64,
        "Rouge": 24.5
      },
      "JMMMU": {
        "Acc": 0.35
      }
    }
  },
  {
    "model": "Efficient-Large-Model/VILA1.5-13b",
    "url": "https://huggingface.co/Efficient-Large-Model/VILA1.5-13b",
    "scores": {
      "Heron": {
        "LLM": 46.93
      },
      "VG-VQA": {
        "LLM": 3.23,
        "Rouge": 12.97
      },
      "MECHA": {
        "Acc": 0.46
      },
      "MMMU": {
        "Acc": 0.37
      },
      "JVB-ItW": {
        "LLM": 3.48,
        "Rouge": 42.49
      },
      "LLAVA": {
        "LLM": 3.6,
        "Rouge": 34.96
      },
      "JDocQA": {
        "Acc": 0.15,
        "LLM": 2.22
      },
      "MulIm-VQA": {
        "LLM": 3.16,
        "Rouge": 40.01
      },
      "JMMMU": {
        "Acc": 0.33
      }
    }
  },
  {
    "model": "OpenGVLab/InternVL2-8B",
    "url": "https://huggingface.co/OpenGVLab/InternVL2-8B",
    "scores": {
      "Heron": {
        "LLM": 49.82
      },
      "VG-VQA": {
        "LLM": 3.48,
        "Rouge": 11.66
      },
      "JIC": {
        "Acc": 0.66
      },
      "MECHA": {
        "Acc": 0.51
      },
      "MMMU": {
        "Acc": 0.5
      },
      "JVB-ItW": {
        "LLM": 3.52,
        "Rouge": 33.79
      },
      "LLAVA": {
        "LLM": 3.07,
        "Rouge": 31.47
      },
      "JDocQA": {
        "Acc": 0.2,
        "LLM": 2.7
      },
      "MulIm-VQA": {
        "LLM": 2.89,
        "Rouge": 34.48
      },
      "JMMMU": {
        "Acc": 0.39
      }
    }
  },
  {
    "model": "OpenGVLab/InternVL2-26B",
    "url": "https://huggingface.co/OpenGVLab/InternVL2-26B",
    "scores": {
      "Heron": {
        "LLM": 59.69
      },
      "VG-VQA": {
        "LLM": 3.65,
        "Rouge": 11.58
      },
      "JIC": {
        "Acc": 0.74
      },
      "MECHA": {
        "Acc": 0.51
      },
      "MMMU": {
        "Acc": 0.48
      },
      "JVB-ItW": {
        "LLM": 3.08,
        "Rouge": 26.74
      },
      "LLAVA": {
        "LLM": 3.75,
        "Rouge": 30.55
      },
      "JDocQA": {
        "Acc": 0.15,
        "LLM": 2.6
      },
      "MulIm-VQA": {
        "LLM": 3.31,
        "Rouge": 45.4
      },
      "JMMMU": {
        "Acc": 0.39
      }
    }
  },
  {
    "model": "Qwen/Qwen2.5-VL-7B-Instruct",
    "url": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "scores": {
      "Heron": {
        "LLM": 70.29
      },
      "VG-VQA": {
        "LLM": 3.69,
        "Rouge": 8.99
      },
      "JIC": {
        "Acc": 0.83
      },
      "MECHA": {
        "Acc": 0.6
      },
      "MMMU": {
        "Acc": 0.5
      },
      "JVB-ItW": {
        "LLM": 4.28,
        "Rouge": 29.63
      },
      "LLAVA": {
        "LLM": 3.93,
        "Rouge": 27.13
      },
      "JDocQA": {
        "Acc": 0.26,
        "LLM": 3.59
      },
      "MulIm-VQA": {
        "LLM": 4.11,
        "Rouge": 50.37
      },
      "JMMMU": {
        "Acc": 0.48
      }
    }
  },
  {
    "model": "Qwen/Qwen2.5-VL-72B-Instruct",
    "url": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "scores": {
      "Heron": {
        "LLM": 85.46
      },
      "VG-VQA": {
        "LLM": 3.89,
        "Rouge": 9.83
      },
      "JIC": {
        "Acc": 0.9
      },
      "MECHA": {
        "Acc": 0.75
      },
      "MMMU": {
        "Acc": 0.63
      },
      "JVB-ItW": {
        "LLM": 4.4,
        "Rouge": 32.04
      },
      "LLAVA": {
        "LLM": 4.05,
        "Rouge": 28.67
      },
      "JDocQA": {
        "Acc": 0.24,
        "LLM": 3.89
      },
      "MulIm-VQA": {
        "LLM": 4.8,
        "Rouge": 60.86
      },
      "JMMMU": {
        "Acc": 0.61
      }
    }
  },
  {
    "model": "google/gemma-3-4b-it",
    "url": "https://huggingface.co/google/gemma-3-4b-it",
    "scores": {
      "Heron": {
        "LLM": 52.83
      },
      "VG-VQA": {
        "LLM": 3.43,
        "Rouge": 12.46
      },
      "JIC": {
        "Acc": 0.75
      },
      "MECHA": {
        "Acc": 0.47
      },
      "MMMU": {
        "Acc": 0.41
      },
      "JVB-ItW": {
        "LLM": 3.68,
        "Rouge": 37.14
      },
      "LLAVA": {
        "LLM": 3.57,
        "Rouge": 22.13
      },
      "JDocQA": {
        "Acc": 0.18,
        "LLM": 2.59
      },
      "MulIm-VQA": {
        "LLM": 3.71,
        "Rouge": 52.69
      },
      "JMMMU": {
        "Acc": 0.37
      }
    }
  },
  {
    "model": "google/gemma-3-12b-it",
    "url": "https://huggingface.co/google/gemma-3-12b-it",
    "scores": {
      "Heron": {
        "LLM": 72.19
      },
      "VG-VQA": {
        "LLM": 3.74,
        "Rouge": 12.49
      },
      "JIC": {
        "Acc": 0.86
      },
      "MECHA": {
        "Acc": 0.63
      },
      "MMMU": {
        "Acc": 0.48
      },
      "JVB-ItW": {
        "LLM": 4.3,
        "Rouge": 35.68
      },
      "LLAVA": {
        "LLM": 4.02,
        "Rouge": 22.11
      },
      "JDocQA": {
        "Acc": 0.2,
        "LLM": 2.98
      },
      "MulIm-VQA": {
        "LLM": 4.22,
        "Rouge": 59.66
      },
      "JMMMU": {
        "Acc": 0.48
      }
    }
  },
  {
    "model": "google/gemma-3-27b-it",
    "url": "https://huggingface.co/google/gemma-3-27b-it",
    "scores": {
      "Heron": {
        "LLM": 69.15
      },
      "VG-VQA": {
        "LLM": 3.75,
        "Rouge": 10.91
      },
      "JIC": {
        "Acc": 0.88
      },
      "MECHA": {
        "Acc": 0.68
      },
      "MMMU": {
        "Acc": 0.56
      },
      "JVB-ItW": {
        "LLM": 4.36,
        "Rouge": 30.89
      },
      "LLAVA": {
        "LLM": 3.93,
        "Rouge": 21.07
      },
      "JDocQA": {
        "Acc": 0.2,
        "LLM": 3.1
      },
      "MulIm-VQA": {
        "LLM": 4.33,
        "Rouge": 56.29
      },
      "JMMMU": {
        "Acc": 0.51
      }
    }
  },
  {
    "model": "microsoft/Phi-4-multimodal-instruct",
    "url": "https://huggingface.co/microsoft/Phi-4-multimodal-instruct",
    "scores": {
      "Heron": {
        "LLM": 45.52
      },
      "VG-VQA": {
        "LLM": 3.3,
        "Rouge": 19.0
      },
      "JIC": {
        "Acc": 0.52
      },
      "MECHA": {
        "Acc": 0.46
      },
      "MMMU": {
        "Acc": 0.54
      },
      "JVB-ItW": {
        "LLM": 3.2,
        "Rouge": 26.8
      },
      "LLAVA": {
        "LLM": 3.37,
        "Rouge": 29.48
      },
      "JDocQA": {
        "Acc": 0.23,
        "LLM": 2.9
      },
      "MulIm-VQA": {
        "LLM": 3.38,
        "Rouge": 42.34
      },
      "JMMMU": {
        "Acc": 0.39
      }
    }
  },
  {
    "model": "gpt-4o-2024-11-20",
    "url": "https://huggingface.co/gpt-4o-2024-11-20",
    "scores": {
      "Heron": {
        "LLM": 93.7
      },
      "VG-VQA": {
        "LLM": 3.93,
        "Rouge": 11.77
      },
      "JIC": {
        "Acc": 0.96
      },
      "MECHA": {
        "Acc": 0.84
      },
      "MMMU": {
        "Acc": 0.56
      },
      "JVB-ItW": {
        "LLM": 4.44,
        "Rouge": 32.2
      },
      "LLAVA": {
        "LLM": 4.13,
        "Rouge": 29.77
      },
      "JDocQA": {
        "Acc": 0.22,
        "LLM": 3.59
      },
      "MulIm-VQA": {
        "LLM": 4.75,
        "Rouge": 62.51
      },
      "JMMMU": {
        "Acc": 0.57
      }
    }
  }
]