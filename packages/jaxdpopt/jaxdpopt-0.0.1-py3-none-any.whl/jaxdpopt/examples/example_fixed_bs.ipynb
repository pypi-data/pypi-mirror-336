{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Notebook\n",
    "\n",
    "In this notebook we show how to use the library to implement computionally-efficient DP-SGD with JAX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup (skip until 1. if you don't need the details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "import jax\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Enviroment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".90\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "\n",
    "jax.clear_caches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Use GPU or CPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Arguments\n",
    "\n",
    "Here you can change the value of the arguments by changing the default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used args: Namespace(lr=0.001, num_steps=10, logical_bs=100, clipping_norm=1, target_epsilon=8, target_delta=1e-05, physical_bs=2, accountant='pld', seed=1234)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--lr\", default=0.001, type=float, help=\"learning rate\")\n",
    "parser.add_argument(\"--num_steps\", default=10, type=int, help=\"Number of steps\")\n",
    "parser.add_argument(\"--logical_bs\", default=100, type=int, help=\"Logical batch size\")\n",
    "parser.add_argument(\"--clipping_norm\", default=1, type=float, help=\"max grad norm\")\n",
    "\n",
    "parser.add_argument(\"--target_epsilon\", default=8, type=float, help=\"target epsilon\")\n",
    "parser.add_argument(\"--target_delta\", default=1e-5, type=float, help=\"target delta\")\n",
    "\n",
    "parser.add_argument(\"--physical_bs\", default=2, type=int, help=\"Physical Batch Size\")\n",
    "parser.add_argument(\"--accountant\", default=\"pld\", type=str, help=\"The privacy accountant for DP training.\")\n",
    "\n",
    "parser.add_argument(\"--seed\", default=1234, type=int)\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "print(\"Used args:\", args, flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setting up dataset, model and DP accounting\n",
    "We show you how to setup the dataset, model and how the DP accounting works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Dataset\n",
    "\n",
    "We load the dataset from [Hugging Face](https://huggingface.co/) but the only important thing is to have the data available as arrays. Hugging Face supports this nicely but there might be other or even better ways to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebarodr/Documents/privacy_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from jaxdpopt.data import load_from_huggingface\n",
    "\n",
    "train_images, train_labels, test_images, test_labels = load_from_huggingface(\n",
    "    \"uoft-cs/cifar10\", cache_dir=None, feature_name=\"img\"\n",
    ")\n",
    "ORIG_IMAGE_DIMENSION, RESIZED_IMAGE_DIMENSION = 32, 32\n",
    "N_CHANNELS = 3\n",
    "ORIG_IMAGE_SHAPE = (N_CHANNELS, ORIG_IMAGE_DIMENSION, ORIG_IMAGE_DIMENSION)\n",
    "train_images = train_images[train_labels < 2].transpose(0, 3, 1, 2)\n",
    "train_labels = train_labels[train_labels < 2]\n",
    "test_images = test_images[test_labels < 2].transpose(0, 3, 1, 2)\n",
    "test_labels = test_labels[test_labels < 2]\n",
    "\n",
    "\n",
    "num_classes = 2\n",
    "dataset_size = len(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Model\n",
    "\n",
    "We create a `flax.training.train_state.TrainState` and load pre-trained weights from [Hugging Face](https://huggingface.co/) using the `create_train_state` function that we provide in `src.models.py`. In this particular example, we load the weights of a simple Conv_Net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model name small\n"
     ]
    }
   ],
   "source": [
    "from jaxdpopt.models import create_train_state\n",
    "from collections import namedtuple\n",
    "\n",
    "optimizer_config = namedtuple(\"Config\", [\"learning_rate\"])\n",
    "optimizer_config.learning_rate = args.lr\n",
    "\n",
    "state = create_train_state(\n",
    "    model_name=\"small\",\n",
    "    num_classes=num_classes,\n",
    "    image_dimension=RESIZED_IMAGE_DIMENSION,\n",
    "    optimizer_config=optimizer_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 DP accounting\n",
    "\n",
    "First, we compute the `subsampling_ratio` based on the `dataset_size` and the (expected) `logical_bs`. Then we compute the required DP-SGD `noise_std` based on the `subsampling_ratio` and the `num_steps` for a particular pair of `target_epsilon` and `target_delta` using a privacy accountant. At the moment the Privacy Loss Distributions (PLDs) and RDP accounting from the google [dp_accounting](https://github.com/google/differential-privacy/tree/main/python/dp_accounting) library are supported. \n",
    "\n",
    "*Note: You can also use the accounting tooling of other libraries such as the PyTorch based [opacus](https://github.com/pytorch/opacus).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxdpopt.dp_accounting_utils import calculate_noise\n",
    "if dataset_size * args.target_delta > 1.0:\n",
    "    warnings.warn(\"Your delta might be too high.\")\n",
    "\n",
    "subsampling_ratio = 1 / math.ceil(dataset_size / args.logical_bs)\n",
    "\n",
    "noise_std = calculate_noise(\n",
    "        sample_rate=subsampling_ratio,\n",
    "        target_epsilon=args.target_epsilon,\n",
    "        target_delta=args.target_delta,\n",
    "        steps=args.num_steps,\n",
    "        accountant=args.accountant,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Function to process one physical batch\n",
    "\n",
    "First we define the function that computes per example gradients (`compute_per_example_gradients_physical_batch`) and clips them (`clip_and_accumulate_physical_batch`). This function can be jit compiled and then used in the full training loop later (see 3.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxdpopt.jax_mask_efficient import (\n",
    "    compute_per_example_gradients_physical_batch,\n",
    "    add_trees,\n",
    "    clip_physical_batch,\n",
    "    accumulate_physical_batch,\n",
    "    CrossEntropyLoss\n",
    ")\n",
    "\n",
    "loss_fn = CrossEntropyLoss(state=state,num_classes=num_classes,resizer_fn=lambda x:x)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def process_physical_batch(t, params):\n",
    "    (\n",
    "        state,\n",
    "        accumulated_clipped_grads,\n",
    "        logical_batch_X,\n",
    "        logical_batch_y,\n",
    "        masks,\n",
    "    ) = params\n",
    "    # slice\n",
    "    start_idx = t * args.physical_bs\n",
    "\n",
    "    start_shape = (start_idx,0,) + (0,)*len(ORIG_IMAGE_SHAPE)\n",
    "\n",
    "    batch_shape = (args.physical_bs,1,) + ORIG_IMAGE_SHAPE\n",
    "\n",
    "    pb = jax.lax.dynamic_slice(\n",
    "        logical_batch_X,\n",
    "        start_shape,\n",
    "        batch_shape,\n",
    "    )\n",
    "    yb = jax.lax.dynamic_slice(logical_batch_y, (start_idx,), (args.physical_bs,))\n",
    "    mask = jax.lax.dynamic_slice(masks, (start_idx,), (args.physical_bs,))\n",
    "\n",
    "    # compute grads and clip\n",
    "    per_example_gradients = compute_per_example_gradients_physical_batch(state, pb, yb, loss_fn)\n",
    "    clipped_grads_from_pb = clip_physical_batch(per_example_gradients, args.clipping_norm)\n",
    "    sum_of_clipped_grads_from_pb = accumulate_physical_batch(clipped_grads_from_pb, mask)\n",
    "    accumulated_clipped_grads = add_trees(accumulated_clipped_grads, sum_of_clipped_grads_from_pb)\n",
    "\n",
    "    return (\n",
    "        state,\n",
    "        accumulated_clipped_grads,\n",
    "        logical_batch_X,\n",
    "        logical_batch_y,\n",
    "        masks,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Full training loop\n",
    "\n",
    "The below cell executes the main training loop. It consists of the following parts at every step:\n",
    "\n",
    "- Poission sampling of the logical batch size (`poisson_sample_logical_batch_size`): This gives us the logical batch size using Poisson subsampling.\n",
    "- Rounding up of the logical batch size so that there are full physical batches (`setup_physical_batches`): This rounds up the logical batch size so that it is divisible in full physical batches\n",
    "- Padding of the logical batches (`get_padded_logical_batch`): Here we load the actual images and labels.\n",
    "- Computation of the per sample gradients (`jax.lax.fori_loop` using the previously defined `process_physical_batch`): This efficiently computes the per-example gradients of the logical batch.\n",
    "- Addition of noise (`add_Gaussian_noise`): Add the required noise to the accumulated gradients of the logical batch. \n",
    "- Update of the model (`update_model`): Apply the gradient update to the model weights.\n",
    "\n",
    "At the end of a step the following things are executed:\n",
    "- Computation of the throughput: Compute the number of processed examples divided by the time spent.\n",
    "- Evaluate the model (`model_evaluation`): Compute the test accuracy.\n",
    "- Compute the spent privacy budget (`compute_epsilon`): Compute the spent privacy budget using a privacy accountant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 0: 30.08940151467706\n",
      "accuracy at iteration 0: 0.5320000052452087\n",
      "{'accountant': 'pld', 'epsilon': 5.957165897649239, 'delta': 9.999999999661162e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 1: 71.89429801609089\n",
      "accuracy at iteration 1: 0.48399999737739563\n",
      "{'accountant': 'pld', 'epsilon': 6.508521466852355, 'delta': 9.999999999527538e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 2: 528.8039860407883\n",
      "accuracy at iteration 2: 0.5929999947547913\n",
      "{'accountant': 'pld', 'epsilon': 6.8372466859444465, 'delta': 9.999999999457034e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 3: 480.38226219136476\n",
      "accuracy at iteration 3: 0.6455000042915344\n",
      "{'accountant': 'pld', 'epsilon': 7.0804913276558, 'delta': 9.999999999435226e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 4: 520.2385928528814\n",
      "accuracy at iteration 4: 0.6754999756813049\n",
      "{'accountant': 'pld', 'epsilon': 7.279153079860686, 'delta': 9.999999999458479e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 5: 513.6804977220398\n",
      "accuracy at iteration 5: 0.684499979019165\n",
      "{'accountant': 'pld', 'epsilon': 7.45076572702392, 'delta': 9.999999999446658e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 6: 512.8125374433612\n",
      "accuracy at iteration 6: 0.703000009059906\n",
      "{'accountant': 'pld', 'epsilon': 7.604355765691662, 'delta': 9.999999999442123e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 7: 527.6524438953879\n",
      "accuracy at iteration 7: 0.6970000267028809\n",
      "{'accountant': 'pld', 'epsilon': 7.745119948919502, 'delta': 9.9999999994453e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 8: 364.1410445072428\n",
      "accuracy at iteration 8: 0.7149999737739563\n",
      "{'accountant': 'pld', 'epsilon': 7.876283997903011, 'delta': 9.999999999447629e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 9: 259.8102543899423\n",
      "accuracy at iteration 9: 0.7279999852180481\n",
      "{'accountant': 'pld', 'epsilon': 7.999960966050672, 'delta': 9.999999999438882e-06}\n"
     ]
    }
   ],
   "source": [
    "from jaxdpopt.dp_accounting_utils import compute_epsilon\n",
    "from jaxdpopt.jax_mask_efficient import (\n",
    "    get_padded_logical_batch,\n",
    "    model_evaluation,\n",
    "    add_Gaussian_noise,\n",
    "    poisson_sample_logical_batch_size,\n",
    "    setup_physical_batches,\n",
    "    update_model,\n",
    ")\n",
    "\n",
    "times = []\n",
    "logical_batch_sizes = []\n",
    "\n",
    "for t in range(args.num_steps):\n",
    "    sampling_rng = jax.random.key(t + 1)\n",
    "    batch_rng, binomial_rng, noise_rng = jax.random.split(sampling_rng, 3)\n",
    "\n",
    "    #######\n",
    "    # poisson subsample\n",
    "    actual_batch_size = dataset_size * subsampling_ratio\n",
    "\n",
    "    # determine padded_logical_bs so that there are full physical batches\n",
    "    # and create appropriate masks to mask out unnessary elements later\n",
    "    masks, n_physical_batches = setup_physical_batches(\n",
    "        actual_logical_batch_size=actual_batch_size,\n",
    "        physical_bs=args.physical_bs,\n",
    "    )\n",
    "\n",
    "    # get random padded logical batches that are slighly larger actual batch size\n",
    "    padded_logical_batch_X, padded_logical_batch_y = get_padded_logical_batch(\n",
    "        batch_rng=batch_rng,\n",
    "        padded_logical_batch_size=len(masks),\n",
    "        train_X=train_images,\n",
    "        train_y=train_labels,\n",
    "    )\n",
    "\n",
    "    padded_logical_batch_X = padded_logical_batch_X.reshape(-1, 1, 3, ORIG_IMAGE_DIMENSION, ORIG_IMAGE_DIMENSION)\n",
    "\n",
    "    # cast to GPU\n",
    "    if USE_GPU:\n",
    "        padded_logical_batch_X = jax.device_put(padded_logical_batch_X, jax.devices(\"gpu\")[0])\n",
    "        padded_logical_batch_y = jax.device_put(padded_logical_batch_y, jax.devices(\"gpu\")[0])\n",
    "        masks = jax.device_put(masks, jax.devices(\"gpu\")[0])\n",
    "\n",
    "    print(\"##### Starting gradient accumulation #####\", flush=True)\n",
    "    ### gradient accumulation\n",
    "    params = state.params\n",
    "\n",
    "    accumulated_clipped_grads0 = jax.tree.map(lambda x: 0.0 * x, params)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Main loop\n",
    "    _, accumulated_clipped_grads, *_ = jax.lax.fori_loop(\n",
    "        0,\n",
    "        n_physical_batches,\n",
    "        process_physical_batch,\n",
    "        (\n",
    "            state,\n",
    "            accumulated_clipped_grads0,\n",
    "            padded_logical_batch_X,\n",
    "            padded_logical_batch_y,\n",
    "            masks,\n",
    "        ),\n",
    "    )\n",
    "    noisy_grad = add_Gaussian_noise(noise_rng, accumulated_clipped_grads, noise_std, args.clipping_norm)\n",
    "\n",
    "    # update\n",
    "    state = jax.block_until_ready(update_model(state, noisy_grad))\n",
    "\n",
    "    end = time.time()\n",
    "    duration = end - start\n",
    "\n",
    "    times.append(duration)\n",
    "    logical_batch_sizes.append(actual_batch_size)\n",
    "\n",
    "    print(f\"throughput at iteration {t}: {actual_batch_size / duration}\", flush=True)\n",
    "\n",
    "    acc_iter = model_evaluation(\n",
    "        state, test_images, test_labels, batch_size=10, orig_img_shape=ORIG_IMAGE_SHAPE, use_gpu=USE_GPU\n",
    "    )\n",
    "    print(f\"accuracy at iteration {t}: {acc_iter}\", flush=True)\n",
    "\n",
    "    # Compute privacy guarantees\n",
    "    epsilon, delta = compute_epsilon(\n",
    "        noise_multiplier=noise_std,\n",
    "        sample_rate=subsampling_ratio,\n",
    "        steps=t + 1,\n",
    "        target_delta=args.target_delta,\n",
    "        accountant=args.accountant,\n",
    "    )\n",
    "    privacy_results = {\"accountant\": args.accountant, \"epsilon\": epsilon, \"delta\": delta}\n",
    "    print(privacy_results, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Final Model evaluation\n",
    "Here we computate of the throughput (num processed examples/time spent) and final test accuracy (`model_evaluation`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "times \n",
      " [3.3234293460845947, 1.3909308910369873, 0.18910598754882812, 0.20816755294799805, 0.19221949577331543, 0.1946735382080078, 0.19500303268432617, 0.18951869010925293, 0.27461886405944824, 0.38489627838134766]\n",
      "batch sizes \n",
      "  [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
      "accuracy at end of training 0.728\n",
      "throughput 380.95053185737765\n"
     ]
    }
   ],
   "source": [
    "acc_last = model_evaluation(state, test_images, test_labels, batch_size=10, use_gpu=USE_GPU, orig_img_shape=ORIG_IMAGE_SHAPE)\n",
    "\n",
    "print(\"times \\n\", times, flush=True)\n",
    "\n",
    "print(\"batch sizes \\n \", logical_batch_sizes, flush=True)\n",
    "\n",
    "print(\"accuracy at end of training\", acc_last, flush=True)\n",
    "thr = np.mean(np.array(logical_batch_sizes) / np.array(times))\n",
    "print(\"throughput\", thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privacy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
