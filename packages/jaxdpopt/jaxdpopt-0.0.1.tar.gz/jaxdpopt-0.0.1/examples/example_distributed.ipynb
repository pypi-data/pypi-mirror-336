{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Notebook Distributed JAX\n",
    "\n",
    "In this notebook we show how to use the library to implement computionally-efficient DP-SGD with JAX, in a multi-device setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup (skip until 1. if you don't need the details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "import jax\n",
    "\n",
    "import numpy as np\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Enviroment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In case of not having multiple GPUs, trick the compiler to have multiple devices\n",
    "os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=8'\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".90\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "\n",
    "\n",
    "jax.clear_caches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Use GPU or CPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USE_GPU = jax.devices()[0].platform == 'gpu'\n",
    "USE_GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Arguments\n",
    "\n",
    "Here you can change the value of the arguments by changing the default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used args: Namespace(lr=0.001, num_steps=10, logical_bs=100, clipping_norm=1, target_epsilon=8, target_delta=1e-05, physical_bs=2, accountant='pld', seed=1234)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--lr\", default=0.001, type=float, help=\"learning rate\")\n",
    "parser.add_argument(\"--num_steps\", default=10, type=int, help=\"Number of steps\")\n",
    "parser.add_argument(\"--logical_bs\", default=100, type=int, help=\"Logical batch size\")\n",
    "parser.add_argument(\"--clipping_norm\", default=1, type=float, help=\"max grad norm\")\n",
    "\n",
    "parser.add_argument(\"--target_epsilon\", default=8, type=float, help=\"target epsilon\")\n",
    "parser.add_argument(\"--target_delta\", default=1e-5, type=float, help=\"target delta\")\n",
    "\n",
    "parser.add_argument(\"--physical_bs\", default=2, type=int, help=\"Physical Batch Size\")\n",
    "parser.add_argument(\"--accountant\", default=\"pld\", type=str, help=\"The privacy accountant for DP training.\")\n",
    "\n",
    "parser.add_argument(\"--seed\", default=1234, type=int)\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "print(\"Used args:\", args, flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setting up dataset, model and DP accounting\n",
    "We show you how to setup the dataset, model and how the DP accounting works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Dataset\n",
    "\n",
    "We load the dataset from [Hugging Face](https://huggingface.co/) but the only important thing is to have the data available as arrays. Hugging Face supports this nicely but there might be other or even better ways to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebarodr/Documents/privacy_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from jaxdpopt.data import load_from_huggingface\n",
    "\n",
    "train_images, train_labels, test_images, test_labels = load_from_huggingface(\n",
    "    \"uoft-cs/cifar10\", cache_dir=None, feature_name=\"img\"\n",
    ")\n",
    "ORIG_IMAGE_DIMENSION, RESIZED_IMAGE_DIMENSION = 32, 32\n",
    "N_CHANNELS = 3\n",
    "ORIG_IMAGE_SHAPE = (N_CHANNELS, ORIG_IMAGE_DIMENSION, ORIG_IMAGE_DIMENSION)\n",
    "train_images = train_images[train_labels < 2].transpose(0, 3, 1, 2)\n",
    "train_labels = train_labels[train_labels < 2]\n",
    "test_images = test_images[test_labels < 2].transpose(0, 3, 1, 2)\n",
    "test_labels = test_labels[test_labels < 2]\n",
    "\n",
    "\n",
    "num_classes = 2\n",
    "dataset_size = len(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Model\n",
    "\n",
    "We create a `flax.training.train_state.TrainState` and load pre-trained weights from [Hugging Face](https://huggingface.co/) using the `create_train_state` function that we provide in `src.models.py`. In this particular example, we load the weights of a simple Conv_Net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model name small\n"
     ]
    }
   ],
   "source": [
    "from jaxdpopt.models import create_train_state\n",
    "from collections import namedtuple\n",
    "\n",
    "optimizer_config = namedtuple(\"Config\", [\"learning_rate\"])\n",
    "optimizer_config.learning_rate = args.lr\n",
    "\n",
    "state = create_train_state(\n",
    "    model_name=\"small\",\n",
    "    num_classes=num_classes,\n",
    "    image_dimension=RESIZED_IMAGE_DIMENSION,\n",
    "    optimizer_config=optimizer_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 DP accounting\n",
    "\n",
    "First, we compute the `subsampling_ratio` based on the `dataset_size` and the (expected) `logical_bs`. Then we compute the required DP-SGD `noise_std` based on the `subsampling_ratio` and the `num_steps` for a particular pair of `target_epsilon` and `target_delta` using a privacy accountant. At the moment the Privacy Loss Distributions (PLDs) and RDP accounting from the google [dp_accounting](https://github.com/google/differential-privacy/tree/main/python/dp_accounting) library are supported. \n",
    "\n",
    "*Note: You can also use the accounting tooling of other libraries such as the PyTorch based [opacus](https://github.com/pytorch/opacus).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxdpopt.dp_accounting_utils import calculate_noise\n",
    "if dataset_size * args.target_delta > 1.0:\n",
    "    warnings.warn(\"Your delta might be too high.\")\n",
    "\n",
    "subsampling_ratio = 1 / math.ceil(dataset_size / args.logical_bs)\n",
    "\n",
    "noise_std = calculate_noise(\n",
    "        sample_rate=subsampling_ratio,\n",
    "        target_epsilon=args.target_epsilon,\n",
    "        target_delta=args.target_delta,\n",
    "        steps=args.num_steps,\n",
    "        accountant=args.accountant,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Function to process one physical batch\n",
    "\n",
    "First we define the function that computes per example gradients (`compute_per_example_gradients_physical_batch`) and clips them (`clip_and_accumulate_physical_batch`). This function can be jit compiled and then used in the full training loop later (see 3.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxdpopt.jax_mask_efficient import (\n",
    "    compute_per_example_gradients_physical_batch,\n",
    "    add_trees,\n",
    "    clip_physical_batch,\n",
    "    accumulate_physical_batch,\n",
    "    CrossEntropyLoss\n",
    ")\n",
    "\n",
    "loss_fn = CrossEntropyLoss(state=state,num_classes=num_classes,resizer_fn=lambda x:x)\n",
    "\n",
    "@jax.jit\n",
    "def process_physical_batch(t, params):\n",
    "    (\n",
    "        state,\n",
    "        accumulated_clipped_grads,\n",
    "        logical_batch_X,\n",
    "        logical_batch_y,\n",
    "        masks,\n",
    "    ) = params\n",
    "    # slice\n",
    "    start_idx = t * args.physical_bs\n",
    "\n",
    "    start_shape = (start_idx,0,) + (0,)*len(ORIG_IMAGE_SHAPE)\n",
    "\n",
    "    batch_shape = (args.physical_bs,1,) + ORIG_IMAGE_SHAPE\n",
    "\n",
    "    pb = jax.lax.dynamic_slice(\n",
    "        logical_batch_X,\n",
    "        start_shape,\n",
    "        batch_shape,\n",
    "    )\n",
    "    yb = jax.lax.dynamic_slice(logical_batch_y, (start_idx,), (args.physical_bs,))\n",
    "    mask = jax.lax.dynamic_slice(masks, (start_idx,), (args.physical_bs,))\n",
    "\n",
    "    # compute grads and clip\n",
    "    per_example_gradients = compute_per_example_gradients_physical_batch(state, pb, yb, loss_fn)\n",
    "    clipped_grads_from_pb = clip_physical_batch(per_example_gradients, args.clipping_norm)\n",
    "    sum_of_clipped_grads_from_pb = accumulate_physical_batch(clipped_grads_from_pb, mask)\n",
    "    accumulated_clipped_grads = add_trees(accumulated_clipped_grads, sum_of_clipped_grads_from_pb)\n",
    "\n",
    "    return (\n",
    "        state,\n",
    "        accumulated_clipped_grads,\n",
    "        logical_batch_X,\n",
    "        logical_batch_y,\n",
    "        masks,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Full training loop\n",
    "\n",
    "The below cell executes the main training loop. It consists of the following parts at every step:\n",
    "\n",
    "- Poission sampling of the logical batch size (`poisson_sample_logical_batch_size`): This gives us the logical batch size using Poisson subsampling.\n",
    "- Rounding up of the logical batch size so that there are full physical batches (`setup_physical_batches`): This rounds up the logical batch size so that it is divisible in full physical batches\n",
    "- Padding of the logical batches (`get_padded_logical_batch`): Here we load the actual images and labels.\n",
    "- Shard the data and model across devices. The data is sharded, it does not need to be explicitly split, with the correct size. The state (model) is replicated across devices.\n",
    "- Computation of the per sample gradients, per device (`jax.lax.fori_loop` using the previously defined `process_physical_batch`): This efficiently computes the per-example gradients of the logical batch.\n",
    "- Aggregate the gradients across devices, using `jax.lax.psum`. \n",
    "- Move the gradients to the first device and process the rest. \n",
    "- Addition of noise (`add_Gaussian_noise`): Add the required noise to the accumulated gradients of the logical batch. \n",
    "- Update of the model (`update_model`): Apply the gradient update to the model weights.\n",
    "\n",
    "At the end of a step the following things are executed:\n",
    "- Computation of the throughput: Compute the number of processed examples divided by the time spent.\n",
    "- Evaluate the model (`model_evaluation`): Compute the test accuracy.\n",
    "- Compute the spent privacy budget (`compute_epsilon`): Compute the spent privacy budget using a privacy accountant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 0: 36.986202239990234\n",
      "accuracy at iteration 0: 0.5569999814033508\n",
      "{'accountant': 'pld', 'epsilon': 5.957165897649239, 'delta': 9.999999999661162e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 1: 258.55126953125\n",
      "accuracy at iteration 1: 0.5099999904632568\n",
      "{'accountant': 'pld', 'epsilon': 6.508521466852355, 'delta': 9.999999999527538e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 2: 886.4669189453125\n",
      "accuracy at iteration 2: 0.6165000200271606\n",
      "{'accountant': 'pld', 'epsilon': 6.8372466859444465, 'delta': 9.999999999457034e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 3: 146.47711181640625\n",
      "accuracy at iteration 3: 0.6269999742507935\n",
      "{'accountant': 'pld', 'epsilon': 7.0804913276558, 'delta': 9.999999999435226e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 4: 779.1146240234375\n",
      "accuracy at iteration 4: 0.6200000047683716\n",
      "{'accountant': 'pld', 'epsilon': 7.279153079860686, 'delta': 9.999999999458479e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 5: 682.75\n",
      "accuracy at iteration 5: 0.6704999804496765\n",
      "{'accountant': 'pld', 'epsilon': 7.45076572702392, 'delta': 9.999999999446658e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 6: 801.3204345703125\n",
      "accuracy at iteration 6: 0.6855000257492065\n",
      "{'accountant': 'pld', 'epsilon': 7.604355765691662, 'delta': 9.999999999442123e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 7: 802.160400390625\n",
      "accuracy at iteration 7: 0.6974999904632568\n",
      "{'accountant': 'pld', 'epsilon': 7.745119948919502, 'delta': 9.9999999994453e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 8: 135.23477172851562\n",
      "accuracy at iteration 8: 0.7120000123977661\n",
      "{'accountant': 'pld', 'epsilon': 7.876283997903011, 'delta': 9.999999999447629e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 9: 905.9346313476562\n",
      "accuracy at iteration 9: 0.7279999852180481\n",
      "{'accountant': 'pld', 'epsilon': 7.999960966050672, 'delta': 9.999999999438882e-06}\n"
     ]
    }
   ],
   "source": [
    "from jaxdpopt.dp_accounting_utils import compute_epsilon\n",
    "from jaxdpopt.jax_mask_efficient import (\n",
    "    get_padded_logical_batch,\n",
    "    model_evaluation,\n",
    "    add_Gaussian_noise,\n",
    "    poisson_sample_logical_batch_size,\n",
    "    setup_physical_batches_distributed,\n",
    "    update_model,\n",
    ")\n",
    "from jaxdpopt.data import prepare_sharding\n",
    "\n",
    "times = []\n",
    "logical_batch_sizes = []\n",
    "\n",
    "#Get the mesh and sharding objects. This process is done only once.\n",
    "mesh, data_shard, model_shard = prepare_sharding()\n",
    "\n",
    "# Main loop\n",
    "# Each device will execute the same loop. It is the same loop as the non-distributed case, \n",
    "# but with the map-reduce of gradients across devices.\n",
    "# The annotation with the shard map is necessary to describe how each parameter is sharded. \n",
    "# If the partition is empty, means that the object is replicated across devices. \n",
    "# If it has an axis, it will be partitioned across the axis.\n",
    "# In this case, there is only one axis, the devices, and only the data will be \n",
    "# partitioned across them. The state and accumulated parameters will be replicated.\n",
    "# The out_specs describes across which axis the result is computed. Here it is empty\n",
    "# it is doing a reduce across devices. If it had the 'devices' it would reduce but for each device\n",
    "@partial(jax.experimental.shard_map.shard_map, \n",
    "            mesh=mesh, \n",
    "            in_specs=(jax.sharding.PartitionSpec(),\n",
    "                    jax.sharding.PartitionSpec(),\n",
    "                    jax.sharding.PartitionSpec(),\n",
    "                    jax.sharding.PartitionSpec('devices'),\n",
    "                    jax.sharding.PartitionSpec('devices'),\n",
    "                    jax.sharding.PartitionSpec('devices')),\n",
    "            out_specs=jax.sharding.PartitionSpec(),\n",
    "            check_rep=False)\n",
    "def get_acc_grads_logical_batch(\n",
    "        n_physical_batches,\n",
    "        state,\n",
    "        accumulated_clipped_grads0,\n",
    "        padded_logical_batch_X,\n",
    "        padded_logical_batch_y,\n",
    "        masks):\n",
    "\n",
    "    _, accumulated_clipped_grads, *_ = jax.lax.fori_loop(\n",
    "        0,\n",
    "        n_physical_batches,\n",
    "        process_physical_batch,\n",
    "        (\n",
    "            state,\n",
    "            accumulated_clipped_grads0,\n",
    "            padded_logical_batch_X,\n",
    "            padded_logical_batch_y,\n",
    "            masks,\n",
    "        ),\n",
    "    )\n",
    "    #Sum the gradients across devices\n",
    "    global_sum_of_clipped_grads = jax.lax.psum(accumulated_clipped_grads, axis_name='devices')\n",
    "\n",
    "    return global_sum_of_clipped_grads\n",
    "\n",
    "# Compile the shard_map function\n",
    "jit_acc_fun = jax.jit(get_acc_grads_logical_batch)\n",
    "\n",
    "n_devices = jax.device_count()\n",
    "\n",
    "for t in range(args.num_steps):\n",
    "    sampling_rng = jax.random.key(t + 1)\n",
    "    batch_rng, binomial_rng, noise_rng = jax.random.split(sampling_rng, 3)\n",
    "\n",
    "    #######\n",
    "    # poisson subsample\n",
    "    actual_batch_size = poisson_sample_logical_batch_size(\n",
    "        binomial_rng=binomial_rng, dataset_size=dataset_size, q=subsampling_ratio\n",
    "    )\n",
    "\n",
    "    # determine padded_logical_bs so that there are full physical batches\n",
    "    # and create appropriate masks to mask out unnessary elements later\n",
    "    # since the distributed case needs to divide the logical batch in the number\n",
    "    # of devices, we need to pad even more\n",
    "    masks, n_physical_batches, worker_size,n_physical_batches_worker = setup_physical_batches_distributed(\n",
    "        actual_logical_batch_size=actual_batch_size,\n",
    "        physical_bs=args.physical_bs,\n",
    "        world_size=n_devices\n",
    "    )\n",
    "    # get random padded logical batches that are slighly larger actual batch size\n",
    "    padded_logical_batch_X, padded_logical_batch_y = get_padded_logical_batch(\n",
    "        batch_rng=batch_rng,\n",
    "        padded_logical_batch_size=len(masks),\n",
    "        train_X=train_images,\n",
    "        train_y=train_labels,\n",
    "    )\n",
    "\n",
    "    padded_logical_batch_X = padded_logical_batch_X.reshape(-1, 1, 3, ORIG_IMAGE_DIMENSION, ORIG_IMAGE_DIMENSION)\n",
    "\n",
    "    #cast to GPU\n",
    "    # Sharding must be different, the put must be to each device\n",
    "    sharded_logical_batch_X = jax.device_put(padded_logical_batch_X,data_shard)\n",
    "    sharded_logical_batch_y = jax.device_put(padded_logical_batch_y,data_shard)\n",
    "    sharded_masks = jax.device_put(masks,data_shard)\n",
    "\n",
    "    #Shard state - Replicate it to each device\n",
    "    shard_state = jax.device_put(state,model_shard)\n",
    "\n",
    "    print(\"##### Starting gradient accumulation #####\", flush=True)\n",
    "    ### gradient accumulation\n",
    "    params = shard_state.params\n",
    "\n",
    "    accumulated_clipped_grads0 = jax.tree.map(lambda x: 0.0 * x, params)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Main distributed loop\n",
    "    accumulated_clipped_grads = jit_acc_fun(n_physical_batches_worker,shard_state,accumulated_clipped_grads0,sharded_logical_batch_X,sharded_logical_batch_y,sharded_masks)\n",
    "\n",
    "    #The rest of the algorithm is applied only on one device\n",
    "    #Get them in the first device and apply noise\n",
    "    accumulated_clipped_grads = jax.device_put(accumulated_clipped_grads,jax.devices()[0])\n",
    "\n",
    "    noisy_grad = add_Gaussian_noise(noise_rng, accumulated_clipped_grads, noise_std, args.clipping_norm)\n",
    "\n",
    "    # update\n",
    "    state = jax.block_until_ready(update_model(state, noisy_grad))\n",
    "\n",
    "    end = time.time()\n",
    "    duration = end - start\n",
    "\n",
    "    times.append(duration)\n",
    "    logical_batch_sizes.append(actual_batch_size)\n",
    "\n",
    "    print(f\"throughput at iteration {t}: {actual_batch_size / duration}\", flush=True)\n",
    "\n",
    "    acc_iter = model_evaluation(\n",
    "        state, test_images, test_labels, batch_size=10, orig_img_shape=ORIG_IMAGE_SHAPE, use_gpu=USE_GPU\n",
    "    )\n",
    "    print(f\"accuracy at iteration {t}: {acc_iter}\", flush=True)\n",
    "\n",
    "    # Compute privacy guarantees\n",
    "    epsilon, delta = compute_epsilon(\n",
    "        noise_multiplier=noise_std,\n",
    "        sample_rate=subsampling_ratio,\n",
    "        steps=t + 1,\n",
    "        target_delta=args.target_delta,\n",
    "        accountant=args.accountant,\n",
    "    )\n",
    "    privacy_results = {\"accountant\": args.accountant, \"epsilon\": epsilon, \"delta\": delta}\n",
    "    print(privacy_results, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Final Model evaluation\n",
    "Here we computate of the throughput (num processed examples/time spent) and final test accuracy (`model_evaluation`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "times \n",
      " [2.217042922973633, 0.34035801887512207, 0.10491085052490234, 0.7509706020355225, 0.10909819602966309, 0.1230318546295166, 0.13477754592895508, 0.12964987754821777, 0.8947403430938721, 0.1037602424621582]\n",
      "batch sizes \n",
      "  [Array(82., dtype=float32), Array(88., dtype=float32), Array(93., dtype=float32), Array(110., dtype=float32), Array(85., dtype=float32), Array(84., dtype=float32), Array(108., dtype=float32), Array(104., dtype=float32), Array(121., dtype=float32), Array(94., dtype=float32)]\n",
      "accuracy at end of training 0.728\n",
      "throughput 543.4996418192188\n"
     ]
    }
   ],
   "source": [
    "acc_last = model_evaluation(state, test_images, test_labels, batch_size=10, use_gpu=USE_GPU, orig_img_shape=ORIG_IMAGE_SHAPE)\n",
    "\n",
    "print(\"times \\n\", times, flush=True)\n",
    "\n",
    "print(\"batch sizes \\n \", logical_batch_sizes, flush=True)\n",
    "\n",
    "print(\"accuracy at end of training\", acc_last, flush=True)\n",
    "thr = np.mean(np.array(logical_batch_sizes) / np.array(times))\n",
    "print(\"throughput\", thr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privacy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
