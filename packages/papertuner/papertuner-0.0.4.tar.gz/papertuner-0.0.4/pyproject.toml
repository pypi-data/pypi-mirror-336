[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "papertuner"
version = "0.0.4"
authors = [{ name = "Your Name", email = "your.email@example.com" }]
description = "A package for creating ML research assistant models through paper dataset creation and model fine-tuning"
readme = "README.md"
requires-python = ">=3.10"
classifiers = [
    "Programming Language :: Python :: 3",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
    "Development Status :: 4 - Beta",
    "Intended Audience :: Science/Research",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]
dependencies = [
    "huggingface_hub==0.29.3",
    "tenacity==9.0.0",
    "PyMuPDF>=1.22.0",
    "arxiv>=1.4.0",
    "openai==1.66.3",
    "tqdm==4.67.1",
    "requests==2.32.3",
    "datasets==3.4.1",
    "sentence-transformers==3.4.1",
    "trl==0.15.2",
    "vllm",
    # Unsloth is conditionally handled below
]

[project.optional-dependencies]
cu118-torch220 = ["unsloth[cu118-torch220]==2025.3.18"] # CUDA 11.8, Torch 2.2
cu118-torch230 = ["unsloth[cu118-torch230]==2025.3.18"] # CUDA 11.8, Torch 2.3
cu118-torch240 = ["unsloth[cu118-torch240]==2025.3.18"] # CUDA 11.8, Torch 2.4
cu118-torch250 = ["unsloth[cu118-torch250]==2025.3.18"] # CUDA 11.8, Torch 2.5

cu121-torch220 = ["unsloth[cu121-torch220]==2025.3.18"] # CUDA 12.1, Torch 2.2
cu121-torch230 = ["unsloth[cu121-torch230]==2025.3.18"] # CUDA 12.1, Torch 2.3
cu121-torch240 = ["unsloth[cu121-torch240]==2025.3.18"] # CUDA 12.1, Torch 2.4
cu121-torch250 = ["unsloth[cu121-torch250]==2025.3.18"] # CUDA 12.1, Torch 2.5

cu124-torch220 = ["unsloth[cu124-torch220]==2025.3.18"] # CUDA 12.4, Torch 2.2
cu124-torch230 = ["unsloth[cu124-torch230]==2025.3.18"] # CUDA 12.4, Torch 2.3
cu124-torch240 = ["unsloth[cu124-torch240]==2025.3.18"] # CUDA 12.4, Torch 2.4
cu124-torch250 = ["unsloth[cu124-torch250]==2025.3.18"] # CUDA 12.4, Torch 2.5

cu118-ampere-torch220 = [
    "unsloth[cu118-ampere-torch220]==2025.3.18",
] # CUDA 11.8 Ampere, Torch 2.2
cu118-ampere-torch230 = [
    "unsloth[cu118-ampere-torch230]==2025.3.18",
] # CUDA 11.8 Ampere, Torch 2.3
cu118-ampere-torch240 = [
    "unsloth[cu118-ampere-torch240]==2025.3.18",
] # CUDA 11.8 Ampere, Torch 2.4
cu118-ampere-torch250 = [
    "unsloth[cu118-ampere-torch250]==2025.3.18",
] # CUDA 11.8 Ampere, Torch 2.5

cu121-ampere-torch220 = [
    "unsloth[cu121-ampere-torch220]==2025.3.18",
] # CUDA 12.1 Ampere, Torch 2.2
cu121-ampere-torch230 = [
    "unsloth[cu121-ampere-torch230]==2025.3.18",
] # CUDA 12.1 Ampere, Torch 2.3
cu121-ampere-torch240 = [
    "unsloth[cu121-ampere-torch240]==2025.3.18",
] # CUDA 12.1 Ampere, Torch 2.4
cu121-ampere-torch250 = [
    "unsloth[cu121-ampere-torch250]==2025.3.18",
] # CUDA 12.1 Ampere, Torch 2.5

cu124-ampere-torch220 = [
    "unsloth[cu124-ampere-torch220]==2025.3.18",
] # CUDA 12.4 Ampere, Torch 2.2
cu124-ampere-torch230 = [
    "unsloth[cu124-ampere-torch230]==2025.3.18",
] # CUDA 12.4 Ampere, Torch 2.3
cu124-ampere-torch240 = [
    "unsloth[cu124-ampere-torch240]==2025.3.18",
] # CUDA 12.4 Ampere, Torch 2.4
cu124-ampere-torch250 = [
    "unsloth[cu124-ampere-torch250]==2025.3.18",
] # CUDA 12.4 Ampere, Torch 2.5

[project.urls]
"Homepage" = "https://github.com/yourusername/papertuner"
"Bug Tracker" = "https://github.com/yourusername/papertuner/issues"
"Documentation" = "https://github.com/yourusername/papertuner#readme"

[project.scripts]
papertuner-dataset = "papertuner.dataset:main"
papertuner-train = "papertuner.train:main"

[tool.setuptools]
packages = ["papertuner"]
