Metadata-Version: 2.4
Name: toxic_comment_classifier
Version: 0.1.2
Summary: A Python library for classifying toxic comments using deep learning.
Author-email: Md Irfan Ali <irfanali29@hotmail.com>
License: MIT
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.6
Description-Content-Type: text/markdown
Requires-Dist: numpy
Requires-Dist: tensorflow
Requires-Dist: pandas
Requires-Dist: scikit-learn

````md
# Toxic Comment Classifier

A Python library for classifying toxic comments using deep learning.

## Installation

```python

pip install toxic-comment-classifier

```

## Usage

### Initialize the Model

```python
from toxic_comment_classifier import ToxicCommentClassifier

# Load the classifier
model = ToxicCommentClassifier()
```

### Classify a Single Comment

```python
text = "You are so dumb and stupid!"
scores = model.classify(text)

print("Toxicity Scores:", scores)
```

**Output Example:**

```python
{
    "toxic": 0.85,
    "severe_toxic": 0.12,
    "obscene": 0.78,
    "threat": 0.05,
    "insult": 0.90,
    "identity_hate": 0.03
}
```

### Get Overall Toxicity Score

```python
toxicity = model.predict(text)
print(f"Overall Toxicity Score: {toxicity:.4f}")
```

### Classify Multiple Comments (Batch Processing)

```python
texts = [
    "I hate this!",
    "You're amazing!",
    "This is the worst thing ever!"
]

predictions = model.predict_batch(texts)

for txt, score in zip(texts, predictions):
    print(f"Text: {txt} --> Toxicity Score: {score:.4f}")
```

## License

This project is licensed under the MIT License.

```
This keeps things clean, structured, and easy to follow! ðŸš€ Let me know if you need any modifications.
```
````
