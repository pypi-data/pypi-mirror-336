"""
Created on January 25, 2017

@author: Claudio Munoz Crego (ESAC)
"""

import os
import sys
import logging
import datetime
import pandas

from esac_juice_pyutils.commons import tds
from soa_report.juice.eps_data.epsoutput import EpsOutput
from soa_report.juice.eps_data.df_data_rate_avg import DfDataRateAverage


class DataRateAverage(DfDataRateAverage):
    """
    This class allows to handle (read, write) date_rate_avg produce as eps_output by MAPPS/EPS Tools
    """

    def __init__(self, input_file_path, read_start=None, experiment_to_ignore=[]):

        # self.__read(input_file_path)

        # self.df = self.get_data_frame_extended(os.path.join(input_file_path))
        self.df = self.get_data_frame(input_file_path, read_start, experiment_to_ignore)

        if self.df is not None:
            self.__get_eps_output_report_time_step__()

            self.start = pandas.to_datetime(self.df['datetime (UTC)'].iloc[0])
            self.end = pandas.to_datetime(self.df['datetime (UTC)'].iloc[-1])

    def __read(self, input_file_path):
        """
        Read and parse date_rate_avg file

        :param input_file_path: path of the input data_rate_avg.out file
        :return data_out: EpsOutput Object
        """

        input_file_path = os.path.expandvars(input_file_path)
        if not os.path.exists(input_file_path):
            logging.error('{} file {} does not exist'.format('data rate average', input_file_path))
            sys.exit()

        data_out = EpsOutput(os.path.basename(input_file_path))

        f = open(input_file_path, 'r')
        for line in f.read().splitlines():  # readlines():

            # event_mask = re.match(r'^([0-9T\-:]{19})\s*([0-9\.]{6,20})',line,re.M|re.I)

            if line.startswith('#'):  # reading file header
                line = line[1:].lstrip()
                metadata_header = line.split(':')[0]

                header_value = ''
                if ':' in line:
                    header_value = line.split(':')[1]
                    if 'Ref_date:' in line:
                        ref_date_str = line.split(':')[1].strip().split('\n')[0]
                        data_out.start_utc = tds.str2datetime(ref_date_str, d_format="%d-%B-%Y")
                        if not data_out.start_utc:
                            sys.exit()

                data_out.header.append(['#', metadata_header, header_value.lstrip()])

            elif line != '':  # Reading values
                if not line[0].isdigit():
                    data_out.data_title.append(line.split(','))
                else:
                    list_of_values = [line.split(',')[0]]
                    list_of_float = [float(x) for x in line.split(',')[1:]]
                    list_of_values.extend(list_of_float)
                    data_out.data_value.append(list_of_values)

        return data_out

    def get_data_frame(self, input_file_path, read_start=None, experiment_to_ignore=[]):
        """
        Return eps data_rate_avg as pandas frames

        :param input_file_path:
        :param read_start: Allow to specify the first time to read
        :param experiment_to_ignore: list of experiment to ignore
        :return: df: panda data frame
        """

        import pandas as pd

        data_out = self.__read(input_file_path)

        # Create data frame keys
        df_keys = []
        for j in range(len(data_out.data_title[0])):
            df_keys.append(data_out.data_title[0][j] + ':' + data_out.data_title[1][j])

        # Fill data frame dictionary
        df_dictionary = {}
        for i in range(len(df_keys)):
            df_dictionary[df_keys[i]] = []
            for line in data_out.data_value:
                df_dictionary[df_keys[i]].append(line[i])

        ref_date = data_out.start_utc
        logging.debug('reference start time = {}'.format(ref_date))

        if ':Elapsed time' in df_dictionary.keys():

            df_dictionary['Elapsed time'] = df_dictionary.pop(':Elapsed time')

            df_dictionary['timedelta (seconds)'] = []
            df_dictionary['datetime (UTC)'] = []

            if ref_date:
                for t in df_dictionary['Elapsed time']:
                    dt = datetime.timedelta(days=int(t[0:3]))\
                         + datetime.timedelta(hours=int(t[4:6]))\
                         + datetime.timedelta(minutes=int(t[7:9]))\
                         + datetime.timedelta(seconds=int(t[10:]))

                    df_dictionary['timedelta (seconds)'].append(dt.total_seconds())
                    df_dictionary['datetime (UTC)'].append(ref_date + dt)

        elif ':Current time' in df_dictionary.keys():

            df_dictionary['Current time'] = df_dictionary.pop(':Current time')

            # df_dictionary['timedelta (seconds)'] = []
            df_dictionary['datetime (UTC)'] = []
            for t in df_dictionary['Current time']:
                date_time = datetime.datetime.strptime(t, "%d-%b-%Y_%H:%M:%S")

                df_dictionary['datetime (UTC)'].append(date_time)

            data_out.start_utc = datetime.datetime.strptime(df_dictionary['Current time'][0], "%d-%b-%Y_%H:%M:%S")

        else:

            logging.error('Please check eps file files format: {}'.format(input_file_path))
            sys.exit()

        df_dictionary = {k: v for k, v in df_dictionary.items() if not k.startswith("JUICE:")}
        for experiment in experiment_to_ignore:
            df_dictionary = {k: v for k, v in df_dictionary.items() if not k.startswith(f"{experiment}:")}

        df = pd.DataFrame(df_dictionary)

        if read_start:
            df = df[df['datetime (UTC)'] >= read_start]
            df.reset_index(drop=True, inplace=True)

        return df

    # def get_data_frame_period(self, df, start_date_time, end_date_time):
    #     """
    #     Extract dataframe for a given period = [start_date_time, end_date_time]
    #     :param start_datetime:
    #     :param end_date_time:
    #     :return:
    #     """
    #     df = df[df['datetime (UTC)'] < end_date_time]
    #
    #     df['datetime (UTC)'] = pandas.to_datetime(df['datetime (UTC)'])
    #     mask = (df['datetime (UTC)'] > start_date_time) & (df['datetime (UTC)'] <= end_date_time)
    #     df = df.loc[mask]
    #
    #     return df

    def get_data_frame_extended(self, input_file_path):
        """
        Return extended eps data_rate_avg as pandas frames
        :param input_file_path:
        :return: df: panda data frame
        """

        self.df = self.get_data_frame(input_file_path)

        dico = get_downlink_accum(self.df)
        # print '\n', dico.keys()
        for dp in dico.keys():
            self.df[dp] = dico[dp]

        dico = get_downlink(self.df)
        # print '\n', dico.keys()
        for dp in dico.keys():
            self.df[dp] = dico[dp]
            # print dp, df_data_average[dp].iloc[-1]
        return self.df


def get_downlink_accum(df, antenna_label='HGA'):
    """
    Build a data frame including eps downlink profiles

    :param df: panda data frame including X_band_Downlink,K_band_Downlink and Total_Downlink
    :param antenna_label: label use to filter antenna values
    :return: dico
    """

    dico = {'Total_Downlink': [0]}
    col_label = '{}:Accum'.format(antenna_label)

    # print df['Elapsed time'][-4:]

    for i in range(1, len(df['datetime (UTC)'])):
        ant_total_downlink = df[col_label][i] - df[col_label][i - 1]
        dico['Total_Downlink'].append(ant_total_downlink)

    return dico


def get_downlink(df, antenna_label='HGA'):
    """
    Build a data frame including eps downlink profiles

    :param df: panda data frame including X_band_Downlink,K_band_Downlink and Total_Downlink
    :param antenna_label: label use to filter antenna values
    :return: dico
    """

    dico = {'Downlink_Total': [0]}
    col_label = '{}:Downlink'.format(antenna_label)

    # print df['Elapsed time'][-4:]

    report_time_step = (df['datetime (UTC)'][1] - df['datetime (UTC)'][0]).total_seconds()
    Kbits_sec_to_Gbits_dt = report_time_step / 1000 / 1000

    for i in range(1, len(df['datetime (UTC)'])):
        total_downlink = df[col_label][i] * Kbits_sec_to_Gbits_dt
        dico['Downlink_Total'].append(total_downlink)

    return dico
