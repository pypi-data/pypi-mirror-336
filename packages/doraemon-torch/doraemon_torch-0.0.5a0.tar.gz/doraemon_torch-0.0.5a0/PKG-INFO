Metadata-Version: 2.2
Name: doraemon-torch
Version: 0.0.5a0
Summary: Doraemon
Home-page: https://github.com/wuji3/Doraemon
Author: duke
Author-email: dk812821001@163.com
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: torchmetrics>=0.11.4
Requires-Dist: opencv-python>=4.7.0.72
Requires-Dist: numpy>=1.24.3
Requires-Dist: tqdm>=4.66.4
Requires-Dist: Pillow>=9.4.0
Requires-Dist: grad-cam>=1.4.8
Requires-Dist: timm>=0.9.16
Requires-Dist: tensorboard>=2.16.2
Requires-Dist: prettytable>=3.10.0
Requires-Dist: datasets>=2.20.0
Requires-Dist: imagehash>=4.3.1
Requires-Dist: transformers>=4.48.3
Requires-Dist: torch>=2.5.1
Requires-Dist: torchvision>=0.20.1
Requires-Dist: torchaudio>=2.5.1
Requires-Dist: faiss-cpu>=1.7.2
Dynamic: author
Dynamic: author-email
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# <div align="center">DORAEMON: Deep Object Recognition And Embedding Model Of Networks</div>

<p align="center">
<img src="./misc/doraemon.jpg">
</p>

<p align="center">
<img src="https://img.shields.io/badge/doraemon-0.0.4a0-brightgreen.svg">
<img src="https://img.shields.io/badge/python-3.10-blue.svg">
<img src="https://img.shields.io/badge/pytorch-2.0+-orange.svg">
<img src="https://img.shields.io/badge/torchmetrics-0.11.4-green.svg">
<img src="https://img.shields.io/badge/timm-0.9.16-red.svg">
<img src="https://img.shields.io/badge/opencv-4.7.0-lightgrey.svg">
<a href="LICENSE"><img src="https://img.shields.io/badge/license-MIT-blue.svg"></a>
</p>

## ðŸš€ Quick Start

<summary><b>Installation Guide</b></summary>

```bash
# Create and activate environment
python -m venv doraemon
source doraemon/bin/activate

# Install Doraemon
pip install doraemon-torch

# If you need to install in editable mode (for development)
pip install -e .
```

## ðŸ“¢ What's New

- ðŸŽ 2025.03.16: Doraemon v0.1.0 released
- ðŸŽ 2024.10.01: Content-Based Image Retrieval (CBIR): Training on a real Amazon product dataset with a complete pipeline for training, end-to-end validation, and visualization. Please check [ImageRetrieval.md](doraemon/models/representation/README_CBIR.md)
- ðŸŽ 2024.04.01: Face Recognition: Based on a cleaned MS-Celeb-1M-v1c with over 70,000 IDs and 3.6 million images, validated with LFW. Includes loss functions like ArcFace, CircleLoss, and MagFace.
- ðŸŽ 2023.06.01: Image Classification (IC): Given the Oxford-IIIT Pet dataset. Supports different learning rates for different layers, hard example mining, multi-label and single-label training, bad case analysis, GradCAM visualization, automatic labeling to aid semi-supervised training, and category-specific data augmentation. Refer to [ImageClassification.md](doraemon/models/classifier/README.md)

## âœ¨ Highlights
- [Optimization Algorithms](doraemon/engine/optimizer.py): Various optimization techniques to enhance model training efficiency, including SGD, Adam, and SAM (Sharpness-Aware Minimization).

- [Data Augmentation](doraemon/dataset/transforms.py): A variety of data augmentation techniques to improve model robustness, such as CutOut, Color-Jitter, and Copy-Paste etc.

- [Regularization](doraemon/engine/optimizer.py): Techniques to prevent overfitting and improve model generalization, including Label Smoothing, OHEM, Focal Loss, and Mixup.

- [Visualization](doraemon/utils/cam.py): Integrated visualization tool to understand model decision-making, featuring GradCAM.

- [Personalized Data Augmentation](doraemon/built/class_augmenter.py): Apply exclusive data augmentation to specific classes with Class-Specific Augmentation.

- [Personalized Hyperparameter Tuning](doraemon/built/layer_optimizer.py): Apply different learning rates to specific layers using Layer-Specific Learning Rates.

## ðŸš€ Deployment API

Doraemon offers incredibly simple yet powerful deployment options:

- **Local API Inference**: Deploy models with just a single weight file (*.pt) - one command setup for high-performance local inference
- **Seamless HuggingFace Integration**: Effortlessly deploy to the Huggingface ecosystem with full support for:
  - `AutoModel.from_pretrained()`
  - `AutoProcessor.from_pretrained()`
  - And all standard Hugging Face API interfaces

For detailed deployment instructions and ready-to-use examples, see our [Deployment Guide](deploy/README.md).

## ðŸ“š Tutorials

For detailed guidance on specific tasks, please refer to the following resources:

- **Image Classification**: If you are working on image classification tasks, please refer to [Doc: Image Classification](doraemon/models/classifier/README.md).

- **Image Retrieval**: For image retrieval tasks, please refer to [Doc: Image Retrieval](doraemon/models/representation/README_CBIR.md).

- **Face Recognition**: Stay tuned.

## ðŸ“Š Datasets

Doraemon integrates the following datasets, allowing users to quickly start training:

- **Image Retrieval**: Available at [Ecommerce Product](https://huggingface.co/datasets/wuji3/image-retrieval)
- **Face Recognition**: Available at [MS-Celeb-1M-v1c](https://huggingface.co/datasets/wuji3/face-recognition)
- **Image Classification**: Available at [Oxford-IIIT Pet](https://huggingface.co/datasets/wuji3/oxford-iiit-pet)

## ðŸ§© Supported Models
 
**Doraemon** now supports 1000+ models through integration with Timm:
 
- All models from `timm.list_models(pretrained=True)`
- Including CLIP, SigLIP, DeiT, BEiT, MAE, EVA, DINO and more

[Model Performance Benchmarks](https://github.com/huggingface/pytorch-image-models/tree/main/results) can help you select the most suitable model by comparing:
- Inference speed
- Training efficiency 
- Accuracy across different datasets
- Parameter count vs performance trade-offs

> For detailed benchmark results, see [@huggingface/pytorch-image-models#1933](https://github.com/huggingface/pytorch-image-models/issues/1933)
