# ======================
# Core Configuration
# ======================

# Environment
# ENVIRONMENT=development
ENVIRONMENT=production
PYTHONUNBUFFERED=1 # This is to prevent Python from buffering stdout and stderr
OAUTHLIB_INSECURE_TRANSPORT=1 # This is to allow OAuth2 to work with http

# Version tag for Docker images in production
VERSION=latest

# GitHub repository (username/repo-name)
GITHUB_REPOSITORY=pyspur-dev/pyspur


# ======================
# Application Configuration
# ======================

# Application Host Configuration
# This is the host that the application will be running on
# By default, the application will be running on

PYSPUR_HOST=0.0.0.0
PYSPUR_PORT=6080


# Backend Configuration
DEBUG=False

# Frontend Configuration

# ======================
# Database Settings
# ======================
# PySpur uses PostgreSQL as the database. By default, the database is hosted in a separate container.
# If you want to use an external database, you can provide the connection details here.
# PostgreSQL Configuration
POSTGRES_DB=pyspur
POSTGRES_USER=pyspur
POSTGRES_PASSWORD=pyspur
POSTGRES_HOST=db
POSTGRES_PORT=5432


# ======================
# Model Provider API Keys
# ======================

# OPENAI_API_KEY=your_openai_api_key
# GEMINI_API_KEY=your_gemini_api_key
# ANTHROPIC_API_KEY=your_anthropic_api_key

# ======================
# OpenAI API URL Configuration
# ======================
# In case you are using OpenAI-compatible API service, you can specify the base URL of the API here
# OPENAI_API_BASE=https://api.openai.com/v1

# ======================
# Ollama Configuration
# ======================

# NOTE:
# if the ollama service is running on port 11434 of the host machine,
# then use http://host.docker.internal:11434 as the base url
# if the ollama service is running on a different host, use the ip address or domain name of the host

# Also make sure the ollama service is configured to accept requests. 
# This can be done setting OLLAMA_HOST=0.0.0.0 environment variable before launching the ollama service.

# OLLAMA_BASE_URL=http://host.docker.internal:11434 


# ======================
# Azure OpenAI Configuration
# ======================

# AZURE_OPENAI_API_KEY=your_azure_openai_api_key
# AZURE_OPENAI_API_BASE=https://your-resource-name.openai.azure.com
# AZURE_OPENAI_API_VERSION=your_azure_openai_api_version
# AZURE_OPENAI_DEPLOYMENT_NAME=your_azure_openai_deployment_name

# ======================

# ======================
# Slack Configuration
# ======================

# SLACK_BOT_TOKEN=your_slack_bot_token # starts with xoxb
# SLACK_USER_TOKEN=your_slack_user_token # starts with xoxp

# ======================

# ======================
# Google configuration
# ======================

# NEXT_PUBLIC_GOOGLE_CLIENT_ID=your_google_client_id # Google OAuth Client ID
# # This environment variable is used to configure Google OAuth for your application.
# # It should be set to the client id obtained from the Google Developer Console.
# # The prefix 'NEXT_PUBLIC_' is used to expose this variable to the frontend,
# # allowing client-side code to access it. 

# ======================

# ======================
# GitHub configuration
# ======================

# GITHUB_ACCESS_TOKEN=your_github_access_token # GitHub Personal Access Token
# # This environment variable is used to configure GitHub OAuth for your application.
# # It should be set to the personal access token obtained from the GitHub Developer Settings.

# ======================

# ======================
# Firecrawl configuration
# ======================

# FIRECRAWL_API_KEY=your_firecrawl_api_key # Firecrawl API Key
# # This environment variable is used to configure Firecrawl API for your application.
# # It should be set to the API key obtained from the Firecrawl Developer Console.

# ======================